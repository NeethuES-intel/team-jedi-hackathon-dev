{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"Team Jedi Hackathon \u00b6 Overview \u00b6 This project allows developers to send a single channel sound file to a sound detection pipeline connected to business logic. The business logic parses the inference results as data that is exported to InfluxDB, a time-series database. This time-series data can then be viewed on a Grafana dashboard and customized to send email notifications. Programming Languages: Python, Golang Technologies used : Docker, Docker Compose, Make, Conda, BentoML, Grafana, InfluxDB Intel OpenSource Technologies used: OpenVino, OpenVino Model Server (OVMS), EdgeX Target System Requirements \u00b6 Disk Space needed Dependencies: \u00b6 Docker v24.0.0 Docker Compose v2.17.3 Golang v1.20 Conda Environment with Python v3.8 Sample Audio File - must be single channel and .wav format Microservice descriptions: \u00b6 BentoML Sound Detection Pipeline \u00b6 TODO: Fill me in Business Logic Application Service \u00b6 TODO: Fill me in Data Export Application Service \u00b6 This is a golang-based EdgeX example that provides the ability to export data from the EdgeX Stack. The example allows EdgeX Events and Reading to be sent to InfluxDB using line protocol. This project utilizes the exporter to take data sent via MQTT on a specified topic and export it to InfluxDB using the MQTT Sender, a topic specific to InfluxDB and Telegraf. How It Works \u00b6 Figure 1: Architecture Diagram In this project, a single-channel, wav-format sound file is sent over REST from the Swagger UI to the BentoML Sound Detection Pipeline container. This container then calls OpenVino Model Server (OVMS) Docker container over gRPC to get the model status. The Sound Detection Pipeline container will then run the Python inferencing and send the inference results over REST to the business logic application service. The business logic container is then responsible for parsing the inference results and sending it via MQTT to the data export service. The Data Export service takes the MQTT results and sends them over MQTT to InfluxDB. InfluxDB is responsible for storing the time-series data that is then visualized in a Grafana dashboard. The Grafana dashboard is configured for viewing inference results and sending email notifications. Get Started \u00b6 Provide step-by-step instructions for getting started. Install the listed dependencies . Configure DOCKER_INFLUXDB_INIT_PASSWORD and DOCKER_INFLUXDB_INIT_ADMIN_TOKEN in the .env file for InfluxDB. Build the business logic container. cd app-sample-service make docker cd .. Build the data export container. cd app-sample-service make docker cd .. Create a Conda working environment, configure it, and activate. conda create -n hackathon_env python = 3 .8 conda activate hackathon_env cd pipelines/sound_classification_demo pip install -r requirements.txt cd ../.. Note Use conda list to verify all packages in requirements.txt are installed. Build the BentoML sound detection pipeline service cd pipelines/sound_classification_demo make build Note To build and run the docker image, the build tag from the make build command is required. The following is the expected output from the build command: Figure 2: BentoML Build Output [Optional] Build the BentoML Docker Image from the pipelines/sound_classification_demo directory. make docker-build BENTO_TAG = <bento_image_name>:<bento_image_tag> Note In the example above, the BENTO_TAG would be BENTO_TAG=sound_classification:r5lystssnwbweb5w . Run the Application \u00b6 Run the stack of services from the project root directory. make run [Optional] Run Portainer for container management. make run-portainer Start the BentoML service from the pipelines/sound_classification_demo directory. Run Method Run Command Locally make serve Docker make docker-run BENTO_TAG=<bento_image_name>:<bento_image_tag> PROJECT_REPO_PATH=<project_repo_path> Note In the example from setup, the BENTO_TAG would be BENTO_TAG=sound_classification:r5lystssnwbweb5w . The PROJECT_REPO_PATH is the full path to the team-jedi-hackathon-dev project. Open the Swagger API UI . Test a POST request to the /classify API by providing the input text as { \"MediaPath\" : \"[PATH]/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav\" , \"ModelPath\" : \"[PATH]/team-jedi-hackathon-dev/models/aclnet/1/aclnet_des_53.xml\" , \"LabelPath\" : \"[PATH]/team-jedi-hackathon-dev/models/aclnet/aclnet_53cl.txt\" , \"GatewayIP\" : \"XXX.XXX.X.X\" , \"Port\" : \"9001\" } Success If the pipeline runs successfully, the Response Code will be 200 and the Response Body will look like Success, inference_results: {'timestamp': '2023-09-13 21:10:31.500582', 'inputVideo': '/home/ejlee/Documents/go-jedi/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav', 'inference': [{'videoTimestamp': '[0.00-1.00]', 'label': 'Gunshot', 'accuracy': '100.00%'}, {'videoTimestamp': '[1.00-2.00]', 'label': 'Door knock', 'accuracy': '15.64%'}], 'latency': 9.321213001385331} To further verify the pipeline ran successfully, check the logs of the BentoML Pipeline container. The example below shows the logs from Portainer Figure 3: Portainer container log screenshot Open the Grafana Dashboard to see the visualization of the inference results. API Documentation \u00b6 If your microservices expose APIs, document each API endpoint, including its purpose, input parameters, expected output, and any authentication/authorization requirements. Provide sample API requests and responses for clarity. Testing \u00b6 Discuss the testing approach you followed for your microservices. Document unit tests, integration tests, and any other types of tests performed. Include instructions on how to run the tests. Summary and Next Steps \u00b6 Note: Provide 2-3 line description of what the user has successfully done and where they should go to as the next step. Troubleshooting \u00b6 Include a section addressing common issues, error handling, and troubleshooting tips.","title":"Overview"},{"location":"index.html#team-jedi-hackathon","text":"","title":"Team Jedi Hackathon"},{"location":"index.html#overview","text":"This project allows developers to send a single channel sound file to a sound detection pipeline connected to business logic. The business logic parses the inference results as data that is exported to InfluxDB, a time-series database. This time-series data can then be viewed on a Grafana dashboard and customized to send email notifications. Programming Languages: Python, Golang Technologies used : Docker, Docker Compose, Make, Conda, BentoML, Grafana, InfluxDB Intel OpenSource Technologies used: OpenVino, OpenVino Model Server (OVMS), EdgeX","title":"Overview"},{"location":"index.html#target-system-requirements","text":"Disk Space needed","title":"Target System Requirements"},{"location":"index.html#dependencies","text":"Docker v24.0.0 Docker Compose v2.17.3 Golang v1.20 Conda Environment with Python v3.8 Sample Audio File - must be single channel and .wav format","title":"Dependencies:"},{"location":"index.html#microservice-descriptions","text":"","title":"Microservice descriptions:"},{"location":"index.html#bentoml-sound-detection-pipeline","text":"TODO: Fill me in","title":"BentoML Sound Detection Pipeline"},{"location":"index.html#business-logic-application-service","text":"TODO: Fill me in","title":"Business Logic Application Service"},{"location":"index.html#data-export-application-service","text":"This is a golang-based EdgeX example that provides the ability to export data from the EdgeX Stack. The example allows EdgeX Events and Reading to be sent to InfluxDB using line protocol. This project utilizes the exporter to take data sent via MQTT on a specified topic and export it to InfluxDB using the MQTT Sender, a topic specific to InfluxDB and Telegraf.","title":"Data Export Application Service"},{"location":"index.html#how-it-works","text":"Figure 1: Architecture Diagram In this project, a single-channel, wav-format sound file is sent over REST from the Swagger UI to the BentoML Sound Detection Pipeline container. This container then calls OpenVino Model Server (OVMS) Docker container over gRPC to get the model status. The Sound Detection Pipeline container will then run the Python inferencing and send the inference results over REST to the business logic application service. The business logic container is then responsible for parsing the inference results and sending it via MQTT to the data export service. The Data Export service takes the MQTT results and sends them over MQTT to InfluxDB. InfluxDB is responsible for storing the time-series data that is then visualized in a Grafana dashboard. The Grafana dashboard is configured for viewing inference results and sending email notifications.","title":"How It Works"},{"location":"index.html#get-started","text":"Provide step-by-step instructions for getting started. Install the listed dependencies . Configure DOCKER_INFLUXDB_INIT_PASSWORD and DOCKER_INFLUXDB_INIT_ADMIN_TOKEN in the .env file for InfluxDB. Build the business logic container. cd app-sample-service make docker cd .. Build the data export container. cd app-sample-service make docker cd .. Create a Conda working environment, configure it, and activate. conda create -n hackathon_env python = 3 .8 conda activate hackathon_env cd pipelines/sound_classification_demo pip install -r requirements.txt cd ../.. Note Use conda list to verify all packages in requirements.txt are installed. Build the BentoML sound detection pipeline service cd pipelines/sound_classification_demo make build Note To build and run the docker image, the build tag from the make build command is required. The following is the expected output from the build command: Figure 2: BentoML Build Output [Optional] Build the BentoML Docker Image from the pipelines/sound_classification_demo directory. make docker-build BENTO_TAG = <bento_image_name>:<bento_image_tag> Note In the example above, the BENTO_TAG would be BENTO_TAG=sound_classification:r5lystssnwbweb5w .","title":"Get Started"},{"location":"index.html#run-the-application","text":"Run the stack of services from the project root directory. make run [Optional] Run Portainer for container management. make run-portainer Start the BentoML service from the pipelines/sound_classification_demo directory. Run Method Run Command Locally make serve Docker make docker-run BENTO_TAG=<bento_image_name>:<bento_image_tag> PROJECT_REPO_PATH=<project_repo_path> Note In the example from setup, the BENTO_TAG would be BENTO_TAG=sound_classification:r5lystssnwbweb5w . The PROJECT_REPO_PATH is the full path to the team-jedi-hackathon-dev project. Open the Swagger API UI . Test a POST request to the /classify API by providing the input text as { \"MediaPath\" : \"[PATH]/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav\" , \"ModelPath\" : \"[PATH]/team-jedi-hackathon-dev/models/aclnet/1/aclnet_des_53.xml\" , \"LabelPath\" : \"[PATH]/team-jedi-hackathon-dev/models/aclnet/aclnet_53cl.txt\" , \"GatewayIP\" : \"XXX.XXX.X.X\" , \"Port\" : \"9001\" } Success If the pipeline runs successfully, the Response Code will be 200 and the Response Body will look like Success, inference_results: {'timestamp': '2023-09-13 21:10:31.500582', 'inputVideo': '/home/ejlee/Documents/go-jedi/team-jedi-hackathon-dev/media/ak47s_gun_sound_mono.wav', 'inference': [{'videoTimestamp': '[0.00-1.00]', 'label': 'Gunshot', 'accuracy': '100.00%'}, {'videoTimestamp': '[1.00-2.00]', 'label': 'Door knock', 'accuracy': '15.64%'}], 'latency': 9.321213001385331} To further verify the pipeline ran successfully, check the logs of the BentoML Pipeline container. The example below shows the logs from Portainer Figure 3: Portainer container log screenshot Open the Grafana Dashboard to see the visualization of the inference results.","title":"Run the Application"},{"location":"index.html#api-documentation","text":"If your microservices expose APIs, document each API endpoint, including its purpose, input parameters, expected output, and any authentication/authorization requirements. Provide sample API requests and responses for clarity.","title":"API Documentation"},{"location":"index.html#testing","text":"Discuss the testing approach you followed for your microservices. Document unit tests, integration tests, and any other types of tests performed. Include instructions on how to run the tests.","title":"Testing"},{"location":"index.html#summary-and-next-steps","text":"Note: Provide 2-3 line description of what the user has successfully done and where they should go to as the next step.","title":"Summary and Next Steps"},{"location":"index.html#troubleshooting","text":"Include a section addressing common issues, error handling, and troubleshooting tips.","title":"Troubleshooting"},{"location":"Hackathon_documentation_template.html","text":"Name of Product \u00b6 Overview \u00b6 Provide a 2-3 line description of what this product allows the developer to do. NOTE: Keep this section easy to understand. Make it easy for users to understand what the input and output is. Programming Language: Technologies used : NOTE: List the technologies, frameworks, libraries, and tools you utilized in your microservices project Target System Requirements \u00b6 Disk Space needed Other Requirements Microservice descriptions: \u00b6 NOTE: 1. Discuss the interactions between any other microservices and how they communicate (e.g., RESTful APIs, message queues). 2. Describe how data is stored, managed, and shared How It Works \u00b6 NOTE: Provide description, including architecture diagram, of how the product works. All diagrams and screenshots must have alt-text and captions. Figure 1: Architecture Diagram Get Started \u00b6 Provide step-by-step instructions for getting started. NOTE: Keep these easy to run. Avoid coding and manual configurations after installation. The input, or the configuration of the input, must be included in the package. Text. Text with code. code snippet Text with filepath. Go to the name directory. cd name / Text with code and screenshot. code snippet You will see output similar to the following: Figure 2: Product Dashboard Run the Application \u00b6 Provide detailed steps for running the application. Text. Text with code. code snippet API Documentation \u00b6 If your microservices expose APIs, document each API endpoint, including its purpose, input parameters, expected output, and any authentication/authorization requirements. Provide sample API requests and responses for clarity. Testing \u00b6 Discuss the testing approach you followed for your microservices. Document unit tests, integration tests, and any other types of tests performed. Include instructions on how to run the tests. Summary and Next Steps \u00b6 Note: Provide 2-3 line description of what the user has successfully done and where they should go to as the next step. Troubleshooting \u00b6 Include a section addressing common issues, error handling, and troubleshooting tips.","title":"Name of Product"},{"location":"Hackathon_documentation_template.html#name-of-product","text":"","title":"Name of Product"},{"location":"Hackathon_documentation_template.html#overview","text":"Provide a 2-3 line description of what this product allows the developer to do. NOTE: Keep this section easy to understand. Make it easy for users to understand what the input and output is. Programming Language: Technologies used : NOTE: List the technologies, frameworks, libraries, and tools you utilized in your microservices project","title":"Overview"},{"location":"Hackathon_documentation_template.html#target-system-requirements","text":"Disk Space needed Other Requirements","title":"Target System Requirements"},{"location":"Hackathon_documentation_template.html#microservice-descriptions","text":"NOTE: 1. Discuss the interactions between any other microservices and how they communicate (e.g., RESTful APIs, message queues). 2. Describe how data is stored, managed, and shared","title":"Microservice descriptions:"},{"location":"Hackathon_documentation_template.html#how-it-works","text":"NOTE: Provide description, including architecture diagram, of how the product works. All diagrams and screenshots must have alt-text and captions. Figure 1: Architecture Diagram","title":"How It Works"},{"location":"Hackathon_documentation_template.html#get-started","text":"Provide step-by-step instructions for getting started. NOTE: Keep these easy to run. Avoid coding and manual configurations after installation. The input, or the configuration of the input, must be included in the package. Text. Text with code. code snippet Text with filepath. Go to the name directory. cd name / Text with code and screenshot. code snippet You will see output similar to the following: Figure 2: Product Dashboard","title":"Get Started"},{"location":"Hackathon_documentation_template.html#run-the-application","text":"Provide detailed steps for running the application. Text. Text with code. code snippet","title":"Run the Application"},{"location":"Hackathon_documentation_template.html#api-documentation","text":"If your microservices expose APIs, document each API endpoint, including its purpose, input parameters, expected output, and any authentication/authorization requirements. Provide sample API requests and responses for clarity.","title":"API Documentation"},{"location":"Hackathon_documentation_template.html#testing","text":"Discuss the testing approach you followed for your microservices. Document unit tests, integration tests, and any other types of tests performed. Include instructions on how to run the tests.","title":"Testing"},{"location":"Hackathon_documentation_template.html#summary-and-next-steps","text":"Note: Provide 2-3 line description of what the user has successfully done and where they should go to as the next step.","title":"Summary and Next Steps"},{"location":"Hackathon_documentation_template.html#troubleshooting","text":"Include a section addressing common issues, error handling, and troubleshooting tips.","title":"Troubleshooting"}]}